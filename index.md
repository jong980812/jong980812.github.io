---
layout: default
title: Research Homepage
---

<style>
/* Fixed Navigation Bar */
.navbar {
    position: fixed;
    top: 0;
    width: 100%;
    background: #003366;
    padding: 10px 0;
    z-index: 1000;
    text-align: center;
}
.navbar a {
    color: white;
    padding: 10px 15px;
    text-decoration: none;
    font-weight: bold;
}
.navbar a:hover {
    background: #00509E;
}

/* Section Styles */
.section {
    padding: 80px 20px;
    max-width: 800px;
    margin: auto;
}
</style>

<!-- Navigation Bar -->
<div class="navbar">
    <a href="#home">Home</a>
    <a href="#publications">Publications</a>
    <a href="#projects">Projects</a>
    <a href="#cv">CV</a>
    <a href="#contact">Contact</a>
    <a href="#news">News</a>
</div>

# Research Homepage | Jongseo Lee  
üéì **[KyungHee University](https://www.khu.ac.kr/eng/user/main/view.do)**  
üî¨ **[Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)**  
üíª **Computer Vision Researcher (M.S. Student)**  


---
## üßë‚Äçüíª About Me {#about}

Hello! I am a **Master‚Äôs student in Computer Science** at **Kyung Hee University**, currently in my final semester before graduation.  
I hold dual majors in **Biomedical Engineering and Electronics Engineering**, which have given me a strong interdisciplinary foundation in AI and vision-based research.  

My research is conducted at the **[Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)** under **Professor [Jinwoo Choi](https://sites.google.com/site/jchoivision/)**.  
I primarily focus on:  
- üé• **Video Understanding & Video Action Recognition**  
- üìù **Video-Text Multimodal Learning**  
- üîç **Video Explainable AI (XAI)**  

I am passionate about **developing AI models that not only understand video content but also explain their decision-making process**.  
My recent work explores **how textual and visual information can be integrated for better video comprehension** and how AI can become more **interpretable in video analysis**.  

I am always open to **collaborations and discussions** in computer vision, multimodal AI, and explainability.  
**Feel free to connect with me! üöÄ**  

---



## üì∞ News & Updates {#news}
### üìÖ Feb 2025
- üìù Started a new research project: Video Explainable AI!  


<!-- ### üìÖ January 2024   -->
<!-- - üìù Started a new research project!   -->



---


## ‚úâÔ∏è Contact {#contact}

üìß **Email:** jong980812@khu.ac.kr  

<a href="https://github.com/jong980812" target="_blank" style="text-decoration: none;">
    <img src="https://cdn-icons-png.flaticon.com/512/25/25231.png" width="30" style="vertical-align: middle;"> GitHub
</a>  
<br>
<a href="https://www.linkedin.com/in/jongseo-lee-a551ab244/" target="_blank" style="text-decoration: none;">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" width="30" style="vertical-align: middle;"> LinkedIn
</a>  



## üìÑ Publications {#publications}

#### **Metaverse Interface with Haptic and Rigid Sense Feedback at a Low Cost**  
- **Authors:** **Jongseo Lee**, Su Hyeon Kim, Sun Woong Jang, Jun Yeong Moon, Doug Young Suh  
- **Journal:** Journal of Appropriate Technology, Volume 8(2), 2022  
- **DOI:** [10.37675/jat.2022.00171](https://www.e-jat.org/journal/view.php?doi=10.37675/jat.2022.00171)  
- **Abstract:** This paper proposes a low-cost metaverse interface integrating haptic and force feedback for a more immersive VR experience. It includes modules for tactile feedback, force feedback, motion tracking, and pose estimation.  

---

#### **CAST: Cross-Attention in Space and Time for Video Action Recognition**  
- **Authors:** Dongho Lee, **Jongseo Lee**, Jinwoo Choi  
- **Conference:** NeurIPS 2023  
- **Project Page:** [CAST](https://jong980812.github.io/CAST.github.io/)  
- **Paper Link:** [NeurIPS 2023](https://neurips.cc/virtual/2023/poster/70748)  
- **Abstract:** This paper introduces CAST, a novel cross-attention mechanism for video action recognition, which effectively captures spatial and temporal dependencies.  

---

#### PCEvE: Part Contribution Evaluation Based Model Explanation for Human Figure Drawing Assessment and Beyond**  
- **Authors:** **Jongseo Lee**, Geo Ahn, Seong Tae Kim, Jinwoo Choi  
- **Preprint:** arXiv 2024 (under review)  
- **Paper Link:** [arXiv:2409.18260](https://arxiv.org/abs/2409.18260)  
- **Abstract:** PCEvE is a novel explainable AI framework for human figure drawing assessment. It utilizes part-based Shapley Value evaluation to provide more interpretable and class-level model explanations. The method is validated across multiple datasets and extends beyond human figure analysis to real-world datasets like Stanford Cars.  

---

#### Efficient Video Class Incremental Learning via Class Token Re-Learning**  
- **Authors:** Suhyun Park, **Jongseo Lee**, Jinwoo Choi  
- **Conference:** Korean Institute of Information Scientists and Engineers (KIISE), 2024  
- **Paper Link:** [DBpia](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11862420)  
- **Abstract:** This paper introduces a class token-based re-learning approach for efficient video class incremental learning, aiming to improve model adaptability to new classes while maintaining old knowledge.  

---

<!-- ## üõ†Ô∏è Research Projects {#projects}
### Project 1: **Project Title**  
- **Research Goal:**  
- **Technologies Used:**  
- **Related Papers/Code Links:**  

### Project 2: **Project Title**  
- **Research Goal:**  
- **Technologies Used:**  
- **Related Papers/Code Links:**  

--- -->

<!-- ## üìë Curriculum Vitae (CV) {#cv}
### üéì Education  
- **M.S. in Computer Vision**, [KyungHee University](https://www.khu.ac.kr/eng/user/main/view.do)  
- **Researcher at** [Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)  

üìÑ **[Download CV (PDF)](#)**  

--- -->

<!-- ## ‚úâÔ∏è Contact {#contact}
üìç **Location:** [KyungHee University](https://www.khu.ac.kr/eng/user/main/view.do)  
üî¨ **Lab:** [Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)  
üìß **Email:** your-email@example.com  
üîó **GitHub:** [jong980812](https://github.com/jong980812)  
üîó **LinkedIn:** [Jongseo Lee](https://www.linkedin.com/in/jongseo-lee-a551ab244/)  

--- -->



