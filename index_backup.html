---
layout: default
title: Research Homepage
---



# Research Homepage | Jongseo Lee  
üéì **[KyungHee University](https://www.khu.ac.kr/eng/user/main/view.do)**  
üî¨ **[Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)**  
üíª **Computer Vision Researcher (M.S. Student)**  


---
## üßë‚Äçüíª About Me {#about}

Hello! I am a **Master‚Äôs student in Computer Science** at **Kyung Hee University**, currently in my final semester before graduation.  
I hold dual majors in **Biomedical Engineering and Electronics Engineering**, which have given me a strong interdisciplinary foundation in AI and vision-based research.  

My research is conducted at the **[Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)** under **Professor [Jinwoo Choi](https://sites.google.com/site/jchoivision/)**.  
I primarily focus on:  
- üé• **Video Understanding & Video Action Recognition**  
- üìù **Video-Text Multimodal Learning**  
- üîç **Video Explainable AI (XAI)**  

I am passionate about **developing AI models that not only understand video content but also explain their decision-making process**.  
My recent work explores **how textual and visual information can be integrated for better video comprehension** and how AI can become more **interpretable in video analysis**.  

I am always open to **collaborations and discussions** in computer vision, multimodal AI, and explainability.  
**Feel free to connect with me! üöÄ**  

---



## üì∞ News & Updates {#news}
### üìÖ Feb 2025
- üìù Started a new research project: Video Explainable AI!  


<!-- ### üìÖ January 2024   -->
<!-- - üìù Started a new research project!   -->



---


## ‚úâÔ∏è Contact {#contact}

üìß **Email:** jong980812@khu.ac.kr  

<a href="https://github.com/jong980812" target="_blank" style="text-decoration: none;">
    <img src="https://cdn-icons-png.flaticon.com/512/25/25231.png" width="30" style="vertical-align: middle;"> GitHub
</a>  

<br>
<a href="https://www.linkedin.com/in/jongseo-lee-a551ab244/" target="_blank" style="text-decoration: none;">
    <img src="https://cdn-icons-png.flaticon.com/512/174/174857.png" width="30" style="vertical-align: middle;"> LinkedIn
</a>

<br>

---

<br>
<br>



## üìÑ Publications {#publications}

#### **Metaverse Interface with Haptic and Rigid Sense Feedback at a Low Cost**  
- **Authors:** **Jongseo Lee**, Su Hyeon Kim, Sun Woong Jang, Jun Yeong Moon, Doug Young Suh  
- **Journal:** Journal of Appropriate Technology, Volume 8(2), 2022  
- **DOI:** [10.37675/jat.2022.00171](https://www.e-jat.org/journal/view.php?doi=10.37675/jat.2022.00171)  
- **Abstract:** This paper proposes a low-cost metaverse interface integrating haptic and force feedback for a more immersive VR experience. It includes modules for tactile feedback, force feedback, motion tracking, and pose estimation.  

---

#### **CAST: Cross-Attention in Space and Time for Video Action Recognition**  
- **Authors:** Dongho Lee, **Jongseo Lee**, Jinwoo Choi  
- **Conference:** NeurIPS 2023  
- **Project Page:** [CAST](https://jong980812.github.io/CAST.github.io/)  
- **Paper Link:** [NeurIPS 2023](https://neurips.cc/virtual/2023/poster/70748)  
- **Abstract:** This paper introduces CAST, a novel cross-attention mechanism for video action recognition, which effectively captures spatial and temporal dependencies.  

---

#### PCEvE: Part Contribution Evaluation Based Model Explanation for Human Figure Drawing Assessment and Beyond**  
- **Authors:** **Jongseo Lee**, Geo Ahn, Seong Tae Kim, Jinwoo Choi  
- **Preprint:** arXiv 2024 (under review)  
- [Paper Link](https://arxiv.org/abs/2409.18260)  
- **Abstract:** PCEvE is a novel explainable AI framework for human figure drawing assessment. It utilizes part-based Shapley Value evaluation to provide more interpretable and class-level model explanations. The method is validated across multiple datasets and extends beyond human figure analysis to real-world datasets like Stanford Cars.  

---

#### Efficient Video Class Incremental Learning via Class Token Re-Learning**  
- **Authors:**  **Jongseo Lee**, Suhyun Park, Jinwoo Choi  
- **Conference:** Korean Institute of Information Scientists and Engineers (KIISE), 2024  
- [Paper Link](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11862420)  
- **Abstract:** This paper introduces a class token-based re-learning approach for efficient video class incremental learning, aiming to improve model adaptability to new classes while maintaining old knowledge. 

---

#### Audio-Video Cross Attention for Effective Video Action Recognition
-	**Authors**:  **Jongseo Lee**, Jang Juhyeon, Jinwoo Choi
- **Conference**: Korean Institute of Information Scientists and Engineers (KIISE), 2024
- [Paper Link](https://www.dbpia.co.kr/Journal/articleDetail?nodeId=NODE11862452)
- **Abstract**: This paper presents BAVCA, an innovative audio-video cross-attention model for human action recognition. Unlike traditional models that rely only on visual information, BAVCA effectively integrates auditory cues to enhance recognition accuracy. The model outperforms existing state-of-the-art approaches by leveraging modality interactions.

---



<!-- ## üõ†Ô∏è Research Projects {#projects}
### Project 1: **Project Title**  
- **Research Goal:**  
- **Technologies Used:**  
- **Related Papers/Code Links:**  

### Project 2: **Project Title**  
- **Research Goal:**  
- **Technologies Used:**  
- **Related Papers/Code Links:**  

--- -->

<!-- ## üìë Curriculum Vitae (CV) {#cv}
### üéì Education  
- **M.S. in Computer Vision**, [KyungHee University](https://www.khu.ac.kr/eng/user/main/view.do)  
- **Researcher at** [Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)  

üìÑ **[Download CV (PDF)](#)**  

--- -->

<!-- ## ‚úâÔ∏è Contact {#contact}
üìç **Location:** [KyungHee University](https://www.khu.ac.kr/eng/user/main/view.do)  
üî¨ **Lab:** [Vision and Learning Lab](https://vll.khu.ac.kr/pub.html)  
üìß **Email:** your-email@example.com  
üîó **GitHub:** [jong980812](https://github.com/jong980812)  
üîó **LinkedIn:** [Jongseo Lee](https://www.linkedin.com/in/jongseo-lee-a551ab244/)  

--- -->



